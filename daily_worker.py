import pandas as pd
import gspread
import re
import os
import json
import base64
import requests
import time
from datetime import datetime, timedelta, timezone
from supabase import create_client, Client
from google.oauth2.credentials import Credentials
from google.auth.transport.requests import Request

# --- C·∫§U H√åNH ---
SPREADSHEET_ID = '15Q7_YzBYMjCceBB5-yi51noA0d03oqRIcd-icDvCdqI'
SHEET_NAME_SOURCE = 'KOL PROGRESS'
SHEET_NAME_DASHBOARD = 'KOL DASHBOARD'

# Env Variables
SUPABASE_URL = os.environ.get("SUPABASE_URL", "https://wpzigasfuizrabqqzxln.supabase.co")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "sb_secret_tPw7wEcEku1sVGVITE2X7A_MNtKlCww")
YOUTUBE_API_KEY = os.environ.get("YOUTUBE_API_KEY", "AIzaSyChr_rRRYlsH9_wfY8JB1UJ30fPDMBtp0c")

# --- AUTH SETUP ---
def get_hanoi_time():
    tz_vn = timezone(timedelta(hours=7))
    return datetime.now(tz_vn)

def get_gspread_client():
    SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
    if os.environ.get("TOKEN_JSON_BASE64"):
        print("üîë Auth: Using Github Secret Token...")
        try:
            token_json = base64.b64decode(os.environ.get("TOKEN_JSON_BASE64")).decode('utf-8')
            creds = Credentials.from_authorized_user_info(json.loads(token_json), SCOPES)
        except Exception as e:
            raise Exception(f"‚ùå Token Error: {e}")
    elif os.path.exists('token.json'):
        print("üîë Auth: Using Local token.json...")
        creds = Credentials.from_authorized_user_file('token.json', SCOPES)
    else:
        raise Exception("‚ùå No auth token found!")

    if creds.expired and creds.refresh_token:
        creds.refresh(Request())
    return gspread.authorize(creds)

# Init Clients
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
gc = get_gspread_client()

# --- HELPERS ---
def extract_video_id(url):
    """L·∫•y YouTube ID chu·∫©n t·ª´ m·ªçi ƒë·ªãnh d·∫°ng link"""
    if not isinstance(url, str): return None
    match = re.search(r'(?:v=|\/|youtu\.be\/)([\w-]{11})(?=&|\?|$)', url)
    return match.group(1) if match else None

def extract_all_links(text_blob):
    """T√°ch t·∫•t c·∫£ link t·ª´ cell, handle xu·ªëng d√≤ng, d·∫•u ph·∫©y..."""
    if not text_blob: return []
    # Regex b·∫Øt link http/https k·∫øt th√∫c tr∆∞·ªõc kho·∫£ng tr·∫Øng ho·∫∑c d·∫•u c√¢u
    return re.findall(r'(https?://[^\s,;"\']+)', str(text_blob))

def get_youtube_details(video_id):
    """G·ªçi API l·∫•y Title v√† Date"""
    if not video_id: return None, None
    try:
        url = f"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={video_id}&key={YOUTUBE_API_KEY}"
        res = requests.get(url).json()
        if 'items' in res and len(res['items']) > 0:
            snippet = res['items'][0]['snippet']
            title = snippet.get('title', '')
            published_at = snippet.get('publishedAt', '').split('T')[0] # L·∫•y YYYY-MM-DD
            return title, published_at
    except Exception as e:
        print(f"‚ö†Ô∏è YouTube API Error ({video_id}): {e}")
    return None, None

# --- TASK 1: SYNC NEW VIDEOS (PROGRESS -> SUPABASE) ---
def sync_progress_to_db():
    print("\n>>> TASK 1: Scanning for NEW videos in 'KOL PROGRESS'...")
    
    # 1. L·∫•y danh s√°ch video hi·ªán c√≥ tr√™n DB ƒë·ªÉ so s√°nh (tr√°nh query l·∫∑p)
    try:
        existing_res = supabase.table('videos').select('video_url').execute()
        existing_urls = {item['video_url'] for item in existing_res.data}
        print(f"üìö Database hi·ªán c√≥: {len(existing_urls)} videos.")
    except Exception as e:
        print(f"‚ùå Error fetching existing videos: {e}")
        return

    # 2. ƒê·ªçc Google Sheet
    try:
        sh = gc.open_by_key(SPREADSHEET_ID)
        ws = sh.worksheet(SHEET_NAME_SOURCE)
        rows = ws.get_all_values() # L·∫•y to√†n b·ªô data d·∫°ng m·∫£ng
        # Headers: No(0), Email(1), Name(2), Channel(3), Loc(4), Sub(5), Agreement(6), Package(7), ..., Report Link(11)
    except Exception as e:
        print(f"‚ùå Error reading sheet: {e}")
        return

    new_videos_count = 0
    kol_cache = {} # Cache Name -> ID

    # B·ªè qua d√≤ng header (index 0)
    for i, row in enumerate(rows[1:], start=2):
        # Safety check ƒë·ªô d√†i row
        if len(row) < 12: continue

        kol_name = row[2].strip() # C·ªôt C
        raw_links = row[11].strip() # C·ªôt L (Report Link)
        
        # N·∫øu kh√¥ng c√≥ t√™n KOL ho·∫∑c kh√¥ng c√≥ link -> Skip
        if not kol_name or not raw_links: continue

        # T√°ch link (x·ª≠ l√Ω cell c√≥ nhi·ªÅu link)
        links = extract_all_links(raw_links)
        
        for link in links:
            clean_link = link.strip()
            
            # --- CHECK: N·∫øu link ƒë√£ c√≥ trong DB -> B·ªé QUA ---
            if clean_link in existing_urls:
                continue

            print(f"‚ö° Ph√°t hi·ªán video m·ªõi: {clean_link}")
            
            # --- START PROCESS NEW VIDEO ---
            vid_id_yt = extract_video_id(clean_link)
            if not vid_id_yt: continue

            # A. X·ª≠ l√Ω KOL (Upsert & Get ID)
            kol_id = kol_cache.get(kol_name)
            if not kol_id:
                # Map th√¥ng tin KOL t·ª´ row hi·ªán t·∫°i
                kol_data = {
                    'name': kol_name,
                    'email': row[1].strip(),           # C·ªôt B
                    'country': row[4].strip(),         # C·ªôt E
                    'subscriber_count': row[5].strip() # C·ªôt F
                }
                try:
                    res = supabase.table('kols').upsert(kol_data, on_conflict='name').select().execute()
                    if res.data:
                        kol_id = res.data[0]['id']
                    else:
                        # Fallback select n·∫øu upsert kh√¥ng tr·∫£ data
                        res = supabase.table('kols').select('id').eq('name', kol_name).execute()
                        kol_id = res.data[0]['id']
                    kol_cache[kol_name] = kol_id
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói KOL {kol_name}: {e}")
                    continue

            # B. G·ªçi API l·∫•y th√¥ng tin Video (Title, Date)
            yt_title, yt_date = get_youtube_details(vid_id_yt)
            
            # N·∫øu API fail, d√πng t·∫°m t√™n file/ng√†y hi·ªán t·∫°i (ƒë·ªÉ s·ª≠a sau)
            final_title = yt_title if yt_title else f"Video {vid_id_yt}"
            final_date = yt_date if yt_date else get_hanoi_time().strftime('%Y-%m-%d')

            # C. Insert Video v√†o DB
            video_data = {
                'kol_id': kol_id,
                'video_url': clean_link,
                'title': final_title,
                'released_date': final_date,
                'agreement_link': row[6].strip(), # C·ªôt G
                'total_package': row[7].strip(),  # C·ªôt H
                'status': 'Active'
            }
            
            try:
                supabase.table('videos').upsert(video_data, on_conflict='video_url').execute()
                existing_urls.add(clean_link) # Add v√†o cache local ƒë·ªÉ kh√¥ng add tr√πng trong c√πng 1 l·∫ßn ch·∫°y
                new_videos_count += 1
                print(f"‚úÖ ƒê√£ th√™m video: {final_title}")
            except Exception as e:
                print(f"‚ùå L·ªói insert video: {e}")

    print(f"\nüìä T·ªîNG K·∫æT TASK 1: ƒê√£ sync th√†nh c√¥ng {new_videos_count} video m·ªõi.")

# --- TASK 2: UPDATE VIEW & DASHBOARD (DB -> SHEET DASHBOARD) ---
def update_metrics_and_dashboard():
    print("\n>>> TASK 2: Updating Views & Dashboard...")
    
    # 1. L·∫•y t·∫•t c·∫£ video Active t·ª´ DB
    try:
        # Join b·∫£ng kols ƒë·ªÉ l·∫•y t√™n hi·ªÉn th·ªã dashboard
        videos = supabase.table('videos').select('*, kols(name, country)').eq('status', 'Active').order('released_date', desc=True).execute().data
    except Exception as e:
        print(f"‚ùå L·ªói ƒë·ªçc Supabase: {e}")
        return

    # L·ªçc video c√≥ ID youtube h·ª£p l·ªá
    valid_videos = [v for v in videos if extract_video_id(v['video_url'])]
    print(f"üîç ƒêang check view cho {len(valid_videos)} videos...")

    # 2. Batch Request Youtube API (50 id/l·∫ßn)
    chunk_size = 50
    now_str = get_hanoi_time().strftime('%Y-%m-%d')
    date_7_ago = (get_hanoi_time() - timedelta(days=7)).strftime('%Y-%m-%d')
    
    rows_for_dashboard = []
    
    for i in range(0, len(valid_videos), chunk_size):
        chunk = valid_videos[i:i+chunk_size]
        ids_str = ",".join([extract_video_id(v['video_url']) for v in chunk])
        
        try:
            url = f"https://www.googleapis.com/youtube/v3/videos?part=statistics,snippet&id={ids_str}&key={YOUTUBE_API_KEY}"
            res = requests.get(url).json()
            api_map = {item['id']: item for item in res.get('items', [])}
            
            metrics_upsert = []

            for vid in chunk:
                vid_id_yt = extract_video_id(vid['video_url'])
                yt_data = api_map.get(vid_id_yt)
                
                # Default values (n·∫øu video b·ªã x√≥a/private)
                current_view = vid.get('current_views', 0)
                display_title = vid.get('title', vid['video_url'])
                
                if yt_data:
                    current_view = int(yt_data['statistics'].get('viewCount', 0))
                    # Ti·ªán th·ªÉ update lu√¥n title n·∫øu DB ƒëang sai/c≈©
                    api_title = yt_data['snippet'].get('title')
                    if api_title: display_title = api_title
                
                # --- T√≠nh Growth ---
                # L·∫•y view count c·ªßa 7 ng√†y tr∆∞·ªõc t·ª´ b·∫£ng history (video_metrics)
                # Query n√†y n·∫±m trong loop n√™n h∆°i ch·∫≠m, nh∆∞ng ch√≠nh x√°c. 
                # C√≥ th·ªÉ t·ªëi ∆∞u sau b·∫±ng batch query metrics.
                try:
                    hist = supabase.table('video_metrics').select('view_count')\
                        .eq('video_id', vid['id']).eq('recorded_at', date_7_ago).execute()
                    view_last_week = hist.data[0]['view_count'] if hist.data else current_view
                except:
                    view_last_week = current_view
                
                # N·∫øu video m·ªõi < 7 ng√†y, last week coi nh∆∞ = 0 ho·∫∑c logic tu·ª≥ √Ω
                # Logic: View Last Week l√† s·ªë view t·∫°i th·ªùi ƒëi·ªÉm 7 ng√†y tr∆∞·ªõc.
                # Growth = Current - Last Week
                growth = current_view - view_last_week
                
                # --- Prepare Data Sync ---
                metrics_upsert.append({
                    'video_id': vid['id'],
                    'view_count': current_view,
                    'recorded_at': now_str
                })
                
                # Update l·∫°i Main Table
                supabase.table('videos').update({
                    'current_views': current_view,
                    'last_7_days_views': growth,
                    'title': display_title
                }).eq('id', vid['id']).execute()

                # --- Prepare Dashboard Row ---
                # Link Formula
                title_cell = f'=HYPERLINK("{vid["video_url"]}", "{str(display_title).replace("\"", "\"\"")}")'
                
                # Agreement Formula
                agree_link = vid.get('agreement_link', '')
                agree_cell = f'=HYPERLINK("{agree_link}", "View Contract")' if agree_link else "-"

                kol_name = vid['kols']['name'] if vid.get('kols') else 'Unknown'

                row = [
                    title_cell,         # A: Video Title
                    kol_name,           # B: KOL Name
                    vid['released_date'], # C: Released Date
                    vid.get('content_count', 0), # D (Optional)
                    current_view,       # E: Current Views
                    view_last_week,     # F: View Last Week
                    growth,             # G: Growth
                    agree_cell,         # H: Agreement
                    vid.get('total_package'), # I: Package
                    vid.get('status')   # J: Status
                ]
                rows_for_dashboard.append(row)
            
            # Batch upsert metrics history
            if metrics_upsert:
                supabase.table('video_metrics').upsert(metrics_upsert, on_conflict='video_id,recorded_at').execute()
                
        except Exception as e:
            print(f"‚ùå API Batch Error: {e}")

    # 3. Ghi ra Sheet Dashboard
    if rows_for_dashboard:
        try:
            sh = gc.open_by_key(SPREADSHEET_ID)
            try:
                ws = sh.worksheet(SHEET_NAME_DASHBOARD)
                ws.clear()
            except:
                ws = sh.add_worksheet(title=SHEET_NAME_DASHBOARD, rows=1000, cols=20)
            
            headers = ['Video Title', 'KOL Name', 'Released Date', 'Content #', 'Current Views', 'View Last Week', 'Growth (7d)', 'Agreement', 'Package', 'Status']
            
            ws.update(range_name='A1', values=[headers])
            ws.format('A1:J1', {'textFormat': {'bold': True}, 'horizontalAlignment': 'CENTER', 'backgroundColor': {'red': 0.8, 'green': 0.8, 'blue': 0.8}})
            
            ws.update(range_name='A2', values=rows_for_dashboard, value_input_option='USER_ENTERED')
            
            # Format Numbers (View columns E, F, G)
            ws.format(f'E2:G{len(rows_for_dashboard)+1}', {'numberFormat': {'type': 'NUMBER', 'pattern': '#,##0'}})
            ws.columns_auto_resize(0, 9)
            ws.set_basic_filter(f'A1:J{len(rows_for_dashboard)+1}')
            
            print("‚úÖ Dashboard updated successfully!")
        except Exception as e:
            print(f"‚ùå Error writing to Sheet: {e}")

# --- MAIN ---
if __name__ == "__main__":
    try:
        sync_progress_to_db()
        update_metrics_and_dashboard()
        print("\nüöÄ ALL PROCESS COMPLETED!")
    except Exception as e:
        print(f"\n‚ùå FATAL ERROR: {e}")
